name: ML Pipeline - Train Model and Deploy

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Позволяет запускать workflow вручную

env:
  PYTHON_VERSION: '3.12'
  S3_BUCKET_NAME: ml-model-storage
  S3_ENDPOINT: https://storage.yandexcloud.net
  S3_ACCESS_KEY: ${{ secrets.S3_ACCESS_KEY }}
  S3_SECRET_KEY: ${{ secrets.S3_SECRET_KEY }}

jobs:
  train:
    runs-on: ubuntu-latest
    name: Train Iris Model and Upload to S3
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r src/requirements.txt
        
    - name: Run model training
      env:
        AWS_ACCESS_KEY_ID: ${{ env.S3_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ env.S3_SECRET_KEY }}
        S3_BUCKET_NAME: ml-model-storage
      run: |
        cd src
        python train.py
        
  deploy:
    name: Upload Source code to S3
    runs-on: ubuntu-latest
    steps:
      # загрузка репозитория в runner
      - uses: actions/checkout@v2
      
      # загрузка файлов в S3
      - name: Upload to S3
        uses: jakejarvis/s3-sync-action@master
        with:
          args: --delete
        env:
          AWS_S3_BUCKET: ${{ env.S3_BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ env.S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ env.S3_SECRET_KEY }}
          AWS_S3_ENDPOINT: ${{ env.S3_ENDPOINT }}
          SOURCE_DIR: 'src'
          DEST_DIR: 'src'